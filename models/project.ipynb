{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c43c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "table = pd.read_csv(\"news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e80132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>rubric</th>\n",
       "      <th>subrubric</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Синий богатырь</td>\n",
       "      <td>В 1930-е годы Советский Союз охватила лихорадк...</td>\n",
       "      <td>2020-08-30T00:01:00+03:00</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Госэкономика</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Загитова согласилась вести «Ледниковый период»</td>\n",
       "      <td>Олимпийская чемпионка по фигурному катанию  Ал...</td>\n",
       "      <td>2020-08-31T20:04:00+03:00</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>Зимние виды</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Объяснена опасность однообразного питания</td>\n",
       "      <td>Российский врач-диетолог Римма Мойсенко объясн...</td>\n",
       "      <td>2020-08-31T20:07:00+03:00</td>\n",
       "      <td>Из жизни</td>\n",
       "      <td>Еда</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>«Предохраняться? А зачем?»</td>\n",
       "      <td>В 2019 году телеканал «Ю» запустил адаптацию з...</td>\n",
       "      <td>2020-08-30T00:04:00+03:00</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>ТВ и радио</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Ефремов систематически употреблял наркотики</td>\n",
       "      <td>Актер  Михаил Ефремов  систематически употребл...</td>\n",
       "      <td>2020-08-31T18:27:00+03:00</td>\n",
       "      <td>Культура</td>\n",
       "      <td>Кино</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21668</th>\n",
       "      <td>tjournal.ru</td>\n",
       "      <td>\\n                            Россия прекратил...</td>\n",
       "      <td>\\n\\n    \\n    \\n        \\n        \\n        \\n...</td>\n",
       "      <td>1578056674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>tjournal.ru</td>\n",
       "      <td>\\n                            Во Владивостоке ...</td>\n",
       "      <td>\\n\\n    \\n    \\n        \\n        \\n        \\n...</td>\n",
       "      <td>1577866951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21670</th>\n",
       "      <td>tjournal.ru</td>\n",
       "      <td>\\n                            Дым от австралий...</td>\n",
       "      <td>\\n\\n    \\n    \\n        \\n        \\n        \\n...</td>\n",
       "      <td>1577864124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21671</th>\n",
       "      <td>tjournal.ru</td>\n",
       "      <td>\\n                            Около 200 жителе...</td>\n",
       "      <td>\\n\\n    \\n    \\n        \\n        \\n        \\n...</td>\n",
       "      <td>1577894168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21672</th>\n",
       "      <td>tjournal.ru</td>\n",
       "      <td>\\n                            Папа римский шлё...</td>\n",
       "      <td>\\n\\n    \\n    \\n        \\n        \\n        \\n...</td>\n",
       "      <td>1577893022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21673 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                                              title  \\\n",
       "0         lenta.ru                                     Синий богатырь   \n",
       "1         lenta.ru     Загитова согласилась вести «Ледниковый период»   \n",
       "2         lenta.ru          Объяснена опасность однообразного питания   \n",
       "3         lenta.ru                         «Предохраняться? А зачем?»   \n",
       "4         lenta.ru        Ефремов систематически употреблял наркотики   \n",
       "...            ...                                                ...   \n",
       "21668  tjournal.ru  \\n                            Россия прекратил...   \n",
       "21669  tjournal.ru  \\n                            Во Владивостоке ...   \n",
       "21670  tjournal.ru  \\n                            Дым от австралий...   \n",
       "21671  tjournal.ru  \\n                            Около 200 жителе...   \n",
       "21672  tjournal.ru  \\n                            Папа римский шлё...   \n",
       "\n",
       "                                                    text  \\\n",
       "0      В 1930-е годы Советский Союз охватила лихорадк...   \n",
       "1      Олимпийская чемпионка по фигурному катанию  Ал...   \n",
       "2      Российский врач-диетолог Римма Мойсенко объясн...   \n",
       "3      В 2019 году телеканал «Ю» запустил адаптацию з...   \n",
       "4      Актер  Михаил Ефремов  систематически употребл...   \n",
       "...                                                  ...   \n",
       "21668  \\n\\n    \\n    \\n        \\n        \\n        \\n...   \n",
       "21669  \\n\\n    \\n    \\n        \\n        \\n        \\n...   \n",
       "21670  \\n\\n    \\n    \\n        \\n        \\n        \\n...   \n",
       "21671  \\n\\n    \\n    \\n        \\n        \\n        \\n...   \n",
       "21672  \\n\\n    \\n    \\n        \\n        \\n        \\n...   \n",
       "\n",
       "                publication_date          rubric     subrubric tags  \n",
       "0      2020-08-30T00:01:00+03:00       Экономика  Госэкономика  NaN  \n",
       "1      2020-08-31T20:04:00+03:00           Спорт   Зимние виды  NaN  \n",
       "2      2020-08-31T20:07:00+03:00        Из жизни           Еда  NaN  \n",
       "3      2020-08-30T00:04:00+03:00  Интернет и СМИ    ТВ и радио  NaN  \n",
       "4      2020-08-31T18:27:00+03:00        Культура          Кино  NaN  \n",
       "...                          ...             ...           ...  ...  \n",
       "21668                 1578056674             NaN           NaN  NaN  \n",
       "21669                 1577866951             NaN           NaN  NaN  \n",
       "21670                 1577864124             NaN           NaN  NaN  \n",
       "21671                 1577894168             NaN           NaN  NaN  \n",
       "21672                 1577893022             NaN           NaN  NaN  \n",
       "\n",
       "[21673 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76e7da84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Россия               908\n",
       "Мир                  718\n",
       "Спорт                494\n",
       "Экономика            420\n",
       "Бывший СССР          394\n",
       "Силовые структуры    220\n",
       "Интернет и СМИ       211\n",
       "Наука и техника      208\n",
       "Культура             206\n",
       "Из жизни             197\n",
       "Путешествия          183\n",
       "Ценности             141\n",
       "Дом                  123\n",
       "Нацпроекты            53\n",
       "69-я параллель        27\n",
       "Name: rubric, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['rubric'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "abe9dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = table[(table.rubric != '69-я параллель') & (table.rubric != 'Нацпроекты') & (table.rubric.notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dec495c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>rubric</th>\n",
       "      <th>subrubric</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Синий богатырь</td>\n",
       "      <td>В 1930-е годы Советский Союз охватила лихорадк...</td>\n",
       "      <td>2020-08-30T00:01:00+03:00</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Госэкономика</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Загитова согласилась вести «Ледниковый период»</td>\n",
       "      <td>Олимпийская чемпионка по фигурному катанию  Ал...</td>\n",
       "      <td>2020-08-31T20:04:00+03:00</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>Зимние виды</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Объяснена опасность однообразного питания</td>\n",
       "      <td>Российский врач-диетолог Римма Мойсенко объясн...</td>\n",
       "      <td>2020-08-31T20:07:00+03:00</td>\n",
       "      <td>Из жизни</td>\n",
       "      <td>Еда</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>«Предохраняться? А зачем?»</td>\n",
       "      <td>В 2019 году телеканал «Ю» запустил адаптацию з...</td>\n",
       "      <td>2020-08-30T00:04:00+03:00</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>ТВ и радио</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Ефремов систематически употреблял наркотики</td>\n",
       "      <td>Актер  Михаил Ефремов  систематически употребл...</td>\n",
       "      <td>2020-08-31T18:27:00+03:00</td>\n",
       "      <td>Культура</td>\n",
       "      <td>Кино</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Болгария начала получать газ из «Турецкого пот...</td>\n",
       "      <td>C 1 января Болгария начала получать российский...</td>\n",
       "      <td>2020-01-01T10:24:31+03:00</td>\n",
       "      <td>Экономика</td>\n",
       "      <td>Госэкономика</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>В России изменили правила содержания животных</td>\n",
       "      <td>В России вступили в силу новые правила содержа...</td>\n",
       "      <td>2020-01-01T08:38:00+03:00</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Общество</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4507</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Лазарев объяснил свой проигрыш на «Евровидении»</td>\n",
       "      <td>Российский певец  Сергей Лазарев  объяснил сво...</td>\n",
       "      <td>2020-01-01T07:22:41+03:00</td>\n",
       "      <td>Культура</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>Трамп заявил о нежелании воевать с Ираном</td>\n",
       "      <td>Президент США  Дональд Трамп  заявил о нежелан...</td>\n",
       "      <td>2020-01-01T06:14:10+03:00</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Политика</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>В Совете Безопасности ООН сменились пять госуд...</td>\n",
       "      <td>В состав  Совета Безопасности ООН  вошли пять ...</td>\n",
       "      <td>2020-01-01T05:26:55+03:00</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Политика</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4423 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                                              title  \\\n",
       "0     lenta.ru                                     Синий богатырь   \n",
       "1     lenta.ru     Загитова согласилась вести «Ледниковый период»   \n",
       "2     lenta.ru          Объяснена опасность однообразного питания   \n",
       "3     lenta.ru                         «Предохраняться? А зачем?»   \n",
       "4     lenta.ru        Ефремов систематически употреблял наркотики   \n",
       "...        ...                                                ...   \n",
       "4505  lenta.ru  Болгария начала получать газ из «Турецкого пот...   \n",
       "4506  lenta.ru      В России изменили правила содержания животных   \n",
       "4507  lenta.ru    Лазарев объяснил свой проигрыш на «Евровидении»   \n",
       "4508  lenta.ru          Трамп заявил о нежелании воевать с Ираном   \n",
       "4509  lenta.ru  В Совете Безопасности ООН сменились пять госуд...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     В 1930-е годы Советский Союз охватила лихорадк...   \n",
       "1     Олимпийская чемпионка по фигурному катанию  Ал...   \n",
       "2     Российский врач-диетолог Римма Мойсенко объясн...   \n",
       "3     В 2019 году телеканал «Ю» запустил адаптацию з...   \n",
       "4     Актер  Михаил Ефремов  систематически употребл...   \n",
       "...                                                 ...   \n",
       "4505  C 1 января Болгария начала получать российский...   \n",
       "4506  В России вступили в силу новые правила содержа...   \n",
       "4507  Российский певец  Сергей Лазарев  объяснил сво...   \n",
       "4508  Президент США  Дональд Трамп  заявил о нежелан...   \n",
       "4509  В состав  Совета Безопасности ООН  вошли пять ...   \n",
       "\n",
       "               publication_date          rubric     subrubric tags  \n",
       "0     2020-08-30T00:01:00+03:00       Экономика  Госэкономика  NaN  \n",
       "1     2020-08-31T20:04:00+03:00           Спорт   Зимние виды  NaN  \n",
       "2     2020-08-31T20:07:00+03:00        Из жизни           Еда  NaN  \n",
       "3     2020-08-30T00:04:00+03:00  Интернет и СМИ    ТВ и радио  NaN  \n",
       "4     2020-08-31T18:27:00+03:00        Культура          Кино  NaN  \n",
       "...                         ...             ...           ...  ...  \n",
       "4505  2020-01-01T10:24:31+03:00       Экономика  Госэкономика  NaN  \n",
       "4506  2020-01-01T08:38:00+03:00          Россия      Общество  NaN  \n",
       "4507  2020-01-01T07:22:41+03:00        Культура        Музыка  NaN  \n",
       "4508  2020-01-01T06:14:10+03:00             Мир      Политика  NaN  \n",
       "4509  2020-01-01T05:26:55+03:00             Мир      Политика  NaN  \n",
       "\n",
       "[4423 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf2abbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Россия               908\n",
       "Мир                  718\n",
       "Спорт                494\n",
       "Экономика            420\n",
       "Бывший СССР          394\n",
       "Силовые структуры    220\n",
       "Интернет и СМИ       211\n",
       "Наука и техника      208\n",
       "Культура             206\n",
       "Из жизни             197\n",
       "Путешествия          183\n",
       "Ценности             141\n",
       "Дом                  123\n",
       "Name: rubric, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rubric'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5179e054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4e74f260104c6da89b4ce1091af544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f5af32758d4fd8972e910e2905ac71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14cc3d0444d4ef29c2ecb3f3817a2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccdd56cdd2a4439815677429f6d0d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multi')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "722cbf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3af1e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В 1930-е годы Советский Союз охватила лихорадка — в десятилетие бурной индустриализации повсюду гремели сообщения о новых трудовых подвигах простого народа ради построения коммунизма и светлого будущего. Первым из них стал шахтер из Донбасса  Алексей Стаханов . 85 лет назад он установил рекорд по добыче угля за смену и на следующее утро проснулся знаменитым на весь мир. Его одаривали квартирами и машинами, возили по Союзу, он стал любимцем Сталина, однако в итоге не выдержал славы и спился. Фамилия Стаханов'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['text'][0][:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9af78a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(table['text'][0][:512], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "622370cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1182,  4479,  1011,  1185,  1183, 14150, 29742, 29113,  1196,\n",
       "         19259, 15290, 22919, 29747, 23925, 15414,  1196, 14150, 29757, 29744,\n",
       "          1193, 29750, 25529, 10260, 22919, 10325, 29436, 10260,  1190, 10325,\n",
       "         29750, 14150, 16856, 10260, 29742, 28598,  1517,  1182,  1184, 15290,\n",
       "         29747, 17432, 22919, 10325, 29436, 15290, 22919, 10325, 15290,  1181,\n",
       "         29748, 16856, 18947, 14150, 10325,  1188, 18947, 29742, 29748, 29747,\n",
       "         22919, 16856, 10325, 10260, 29436, 10325, 29744, 10260, 29751, 15414,\n",
       "          1194, 19259, 29747, 29757, 29742, 29748,  1183, 16856, 15290, 29745,\n",
       "         15290, 29436, 10325,  1196, 14150, 14150, 29740, 29754, 15290, 18947,\n",
       "         23483,  1193,  1192, 19259, 29113, 29750,  1197, 16856, 29748, 29742,\n",
       "         19259, 29113, 29750,  1194, 14150, 29742, 25529, 10325, 29741, 10260,\n",
       "         29750,  1194, 16856, 14150, 29747, 22919, 14150, 29741, 14150,  1192,\n",
       "         10260, 16856, 14150, 29742, 10260,  1195, 10260, 29742, 10325,  1194,\n",
       "         14150, 29747, 22919, 16856, 14150, 15290, 18947, 23483,  1189, 14150,\n",
       "         29745, 29745, 29748, 18947, 10325, 29744, 29745, 10260,  1188,  1196,\n",
       "         25529, 15290, 22919, 29436, 14150, 29741, 14150,  1181, 29748, 29742,\n",
       "         29748, 29754, 15290, 29741, 14150,  1012,  1194, 15290, 16856, 25529,\n",
       "         29113, 29745,  1188, 29744,  1192, 10325, 29750,  1196, 22919, 10260,\n",
       "         29436,  1203, 10260, 29750, 22919, 15290, 16856,  1188, 29744,  1184,\n",
       "         14150, 18947, 29740, 10260, 29747, 29747, 10260,  1180, 29436, 15290,\n",
       "         23925, 29747, 15290, 10325,  1196, 22919, 10260, 29750, 28995, 19259,\n",
       "          1012,  5594,  1190, 15290, 22919,  1192, 10260, 29744, 10260, 29742,\n",
       "          1193, 18947,  1198, 29747, 22919, 28995, 19259, 10325, 29436,  1195,\n",
       "         15290, 23925, 14150, 16856, 29742,  1194, 14150,  1184, 14150, 29740,\n",
       "         29113, 29752, 15290,  1198, 29741, 29436, 17432,  1187, 10260,  1196,\n",
       "         29745, 15290, 18947, 29748,  1188,  1192, 10260,  1196, 29436, 15290,\n",
       "         29742, 29748, 29757, 29754, 15290, 15290,  1198, 22919, 16856, 14150,\n",
       "          1194, 16856, 14150, 29747, 18947, 29748, 29436, 29747, 17432,  1187,\n",
       "         19865, 29745, 15290, 18947, 10325, 22919, 29113, 29745,  1192, 10260,\n",
       "          1182, 15290, 29747, 23742,  1191, 10325, 16856,  1012,  1185, 29741,\n",
       "         14150,  1193, 29742, 10260, 16856, 10325, 25529, 10260, 29436, 10325,\n",
       "          1189, 25529, 10260, 16856, 22919, 10325, 16856, 10260, 29745, 10325,\n",
       "          1188,  1191, 10260, 29753, 10325, 19865, 29745, 10325,  1010,  1182,\n",
       "         14150, 29744, 10325, 29436, 10325,  1194, 14150,  1196, 14150, 29757,\n",
       "         29744, 29748,  1010,  1193, 18947,  1196, 22919, 10260, 29436,  1190,\n",
       "         29757, 29740, 10325, 29745, 29751, 15290, 29745,  1196, 22919, 10260,\n",
       "         29436, 10325, 19865,  1010,  1193, 29742, 19865, 23925, 14150,  1182,\n",
       "          1188, 22919, 14150, 29741, 15290,  1192, 15290,  1182, 29113, 29742,\n",
       "         15290, 16856, 29743, 10260, 29436,  1196, 29436, 10260, 25529, 29113,\n",
       "          1188,  1196, 29746, 10325, 29436, 29747, 17432,  1012,  1199, 10260,\n",
       "         29745, 10325, 29436, 23483,  1196, 22919, 10260, 29750, 28995, 19259,\n",
       "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c171ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5c84bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8562db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts, targets, tokenizer, max_len=512):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "          'text': text,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "76c50e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier:\n",
    "\n",
    "    def __init__(self, model_path, tokenizer_path, n_classes=2, epochs=1, model_save_path='bert.pth'):\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_save_path=model_save_path\n",
    "        self.max_len = 512\n",
    "        self.epochs = epochs\n",
    "        self.out_features = self.model.bert.encoder.layer[1].output.dense.out_features\n",
    "        self.model.classifier = torch.nn.Linear(self.out_features, n_classes)\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "    def preparation(self, X_train, y_train, X_valid, y_valid):\n",
    "        # create datasets\n",
    "        self.train_set = CustomDataset(X_train, y_train, self.tokenizer)\n",
    "        self.valid_set = CustomDataset(X_valid, y_valid, self.tokenizer)\n",
    "\n",
    "        # create data loaders\n",
    "        self.train_loader = DataLoader(self.train_set, batch_size=2, shuffle=True)\n",
    "        self.valid_loader = DataLoader(self.valid_set, batch_size=2, shuffle=True)\n",
    "\n",
    "        # helpers initialization\n",
    "        self.optimizer = AdamW(self.model.parameters(), lr=2e-5, correct_bias=False)\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "                self.optimizer,\n",
    "                num_warmup_steps=0,\n",
    "                num_training_steps=len(self.train_loader) * self.epochs\n",
    "            )\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss().to(self.device)\n",
    "            \n",
    "    def fit(self):\n",
    "        self.model = self.model.train()\n",
    "        losses = []\n",
    "        correct_predictions = 0\n",
    "        for data in tqdm(self.train_loader):\n",
    "            input_ids = data[\"input_ids\"].to(self.device)\n",
    "            attention_mask = data[\"attention_mask\"].to(self.device)\n",
    "            targets = data[\"targets\"].to(self.device)\n",
    "\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "                )\n",
    "\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            loss = self.loss_fn(outputs.logits, targets)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "        train_acc = correct_predictions.double() / len(self.train_set)\n",
    "        train_loss = np.mean(losses)\n",
    "        return train_acc, train_loss\n",
    "    \n",
    "    def eval(self):\n",
    "        self.model = self.model.eval()\n",
    "        losses = []\n",
    "        correct_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in self.valid_loader:\n",
    "                input_ids = data[\"input_ids\"].to(self.device)\n",
    "                attention_mask = data[\"attention_mask\"].to(self.device)\n",
    "                targets = data[\"targets\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask\n",
    "                    )\n",
    "\n",
    "                preds = torch.argmax(outputs.logits, dim=1)\n",
    "                loss = self.loss_fn(outputs.logits, targets)\n",
    "                correct_predictions += torch.sum(preds == targets)\n",
    "                losses.append(loss.item())\n",
    "        \n",
    "        val_acc = correct_predictions.double() / len(self.valid_set)\n",
    "        val_loss = np.mean(losses)\n",
    "        return val_acc, val_loss\n",
    "    \n",
    "    def train(self):\n",
    "        best_accuracy = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f'Epoch {epoch + 1}/{self.epochs}')\n",
    "            train_acc, train_loss = self.fit()\n",
    "            print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "            val_acc, val_loss = self.eval()\n",
    "            print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            if val_acc > best_accuracy:\n",
    "                torch.save(self.model, self.model_save_path)\n",
    "                best_accuracy = val_acc\n",
    "\n",
    "        self.model = torch.load(self.model_save_path)\n",
    "    \n",
    "    def predict(self, text):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        out = {\n",
    "              'text': text,\n",
    "              'input_ids': encoding['input_ids'].flatten(),\n",
    "              'attention_mask': encoding['attention_mask'].flatten()\n",
    "          }\n",
    "        \n",
    "        input_ids = out[\"input_ids\"].to(self.device)\n",
    "        attention_mask = out[\"attention_mask\"].to(self.device)\n",
    "        \n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids.unsqueeze(0),\n",
    "            attention_mask=attention_mask.unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "        prediction = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8b6fe7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    if txt is np.NaN or txt == '' or len(txt) == '0' or txt is None:\n",
    "        return None\n",
    "    txt= re.sub('[^a-zA-Zа-яА-Я ]', ' ', str(txt).lower())\n",
    "    txt = re.sub('\\s+', ' ', txt)\n",
    "    txt = txt.replace('.','')\n",
    "    txt = re.sub('\\n', ' ', txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "16e2e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = table[(table.rubric != '69-я параллель') & (table.rubric != 'Нацпроекты') & (table.rubric.notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d7c7750c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475423f2e13f4b41bff8fd61b8e3c91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4423 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/fpn1wtyn1zb56w3_gdn1yg4w0000gn/T/ipykernel_5348/4170807716.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].progress_apply(lambda x :clean_text(x))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47dacba0e4745ec807f01b1c7137c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4423 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/fpn1wtyn1zb56w3_gdn1yg4w0000gn/T/ipykernel_5348/4170807716.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['rubric'] = df['rubric'].progress_apply(lambda x : dict_target[x])\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].progress_apply(lambda x :clean_text(x))\n",
    "uniq = df['rubric'].unique()\n",
    "dict_target = {uniq[i]: i for i in range(len(uniq))}\n",
    "\n",
    "df['rubric'] = df['rubric'].progress_apply(lambda x : dict_target[x])\n",
    "\n",
    "df.rename(columns = {'rubric':'label'}, inplace = True)\n",
    "df.drop(['source', 'title', 'publication_date', 'subrubric', 'tags' ], axis=1 , inplace=True)\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "train, valid = df.iloc[:3000], df.iloc[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8b478940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "classifier = BertClassifier(\n",
    "        model_path='cointegrated/rubert-tiny',\n",
    "        tokenizer_path='cointegrated/rubert-tiny',\n",
    "        n_classes=len(uniq),\n",
    "        epochs=2,\n",
    "        model_save_path='bert.pth'\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b184d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.preparation(\n",
    "        X_train=list(train['text']),\n",
    "        y_train=list(train['label']),\n",
    "        X_valid=list(valid['text']),\n",
    "        y_valid=list(valid['label'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8267b53a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edb6018201f4cc7bd54175249459533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.4845388820817074 accuracy 0.5473333333333333\n",
      "Val loss 1.137637872526192 accuracy 0.6458186929023191\n",
      "----------\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7a9d2908424e7d98eee4fd4a5bd733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.9666346625859539 accuracy 0.7126666666666667\n",
      "Val loss 1.064005653690442 accuracy 0.6669009135628953\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "classifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1827fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
